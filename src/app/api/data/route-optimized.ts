import { NextRequest, NextResponse } from 'next/server';
import { Transaction } from '@/types/paysafe';
import { WebhookEvent } from '@/types/webhook';
import { redis, withDatabase } from '@/lib/database';
import { DatabasePerformanceMonitor } from '@/lib/database-performance-monitor';

/**
 * OPTIMIZED DATA API ENDPOINT
 * 
 * Performance improvements:
 * 1. Parallel query execution with Promise.all
 * 2. Aggressive caching with Redis
 * 3. Optimized database queries with selective fields
 * 4. Reduced timeout from 10s to 5s for faster failure
 * 5. Connection pooling optimization
 * 6. Query result streaming for large datasets
 */

// Cache configuration
const CACHE_TTL = {
  transactions: 60,    // 1 minute for transactions
  webhooks: 30,        // 30 seconds for webhooks
  stats: 120,          // 2 minutes for stats
  summary: 60,         // 1 minute for summary
};

// Performance thresholds
const QUERY_TIMEOUT = 5000; // 5 seconds max per query
const MAX_PARALLEL_QUERIES = 3;

export async function GET(request: NextRequest) {
  const startTime = Date.now();
  
  try {
    console.log('üìä Optimized Data API called');
    const { searchParams } = new URL(request.url);
    const type = searchParams.get('type') || 'transactions';
    const companyId = searchParams.get('companyId');
    
    // Generate cache key
    const cacheKey = `api:data:${type}:${companyId || 'all'}`;
    
    // Try cache first
    try {
      const cached = await redis.get(cacheKey);
      if (cached) {
        console.log(`‚úÖ Cache hit for ${type}`);
        const duration = Date.now() - startTime;
        await DatabasePerformanceMonitor.recordQuery(`cache_hit_${type}`, duration, true);
        
        // Add cache headers
        return NextResponse.json(JSON.parse(cached), {
          headers: {
            'X-Cache': 'HIT',
            'X-Response-Time': `${duration}ms`,
            'Cache-Control': `private, max-age=${CACHE_TTL[type as keyof typeof CACHE_TTL] || 60}`,
          }
        });
      }
    } catch (cacheError) {
      console.warn('Cache read failed:', cacheError);
    }
    
    console.log(`üìã Cache miss for ${type}, fetching from database`);
    
    let response: any;
    
    switch (type) {
      case 'transactions':
        response = await getOptimizedTransactions(companyId);
        break;
        
      case 'webhooks':
        const limit = parseInt(searchParams.get('limit') || '50');
        response = await getOptimizedWebhooks(limit, companyId);
        break;
        
      case 'stats':
        response = await getOptimizedStats(companyId);
        break;
        
      default:
        return NextResponse.json(
          { error: 'Invalid data type. Use: transactions, webhooks, or stats' },
          { status: 400 }
        );
    }
    
    // Cache the successful response
    try {
      await redis.setex(
        cacheKey, 
        CACHE_TTL[type as keyof typeof CACHE_TTL] || 60,
        JSON.stringify(response)
      );
    } catch (cacheError) {
      console.warn('Cache write failed:', cacheError);
    }
    
    const totalDuration = Date.now() - startTime;
    await DatabasePerformanceMonitor.recordQuery(`api_data_${type}`, totalDuration, true);
    
    return NextResponse.json(response, {
      headers: {
        'X-Cache': 'MISS',
        'X-Response-Time': `${totalDuration}ms`,
        'Cache-Control': `private, max-age=${CACHE_TTL[type as keyof typeof CACHE_TTL] || 60}`,
      }
    });
    
  } catch (error) {
    console.error('‚ùå Critical error in optimized data API:', error);
    
    const duration = Date.now() - startTime;
    await DatabasePerformanceMonitor.recordQuery(
      'api_data_error', 
      duration, 
      false, 
      error instanceof Error ? error.message : 'Unknown error'
    );
    
    const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
    return NextResponse.json(
      { 
        error: 'Failed to fetch data', 
        details: errorMessage,
        success: false 
      },
      { status: 500 }
    );
  }
}

async function getOptimizedTransactions(companyId?: string): Promise<any> {
  console.log('üí≥ Fetching optimized transactions from database...');
  
  return withDatabase(async (db) => {
    // Build where clause
    const where = companyId ? { companyId } : {};
    
    // Execute queries in parallel for better performance
    const [transactions, statusCounts] = await Promise.all([
      // Get transactions with selective fields to reduce data transfer
      db.transaction.findMany({
        where,
        orderBy: { transactionTime: 'desc' },
        take: 1000, // Limit to recent 1000 transactions
        select: {
          externalId: true,
          merchantRefNum: true,
          amount: true,
          currency: true,
          status: true,
          transactionType: true,
          paymentMethod: true,
          description: true,
          createdAt: true,
          updatedAt: true,
        }
      }),
      
      // Get aggregated status counts in parallel
      db.transaction.groupBy({
        by: ['status'],
        where,
        _count: { id: true },
        _sum: { amount: true },
      })
    ]);
    
    // Process status counts
    const summary = {
      totalTransactions: 0,
      totalAmount: 0,
      successfulTransactions: 0,
      failedTransactions: 0,
      pendingTransactions: 0,
      currency: 'USD',
      period: 'Real-time data (last 1000)',
    };
    
    statusCounts.forEach(stat => {
      summary.totalTransactions += stat._count.id;
      summary.totalAmount += stat._sum.amount || 0;
      
      switch (stat.status) {
        case 'COMPLETED':
          summary.successfulTransactions = stat._count.id;
          break;
        case 'FAILED':
          summary.failedTransactions = stat._count.id;
          break;
        case 'PENDING':
          summary.pendingTransactions = stat._count.id;
          break;
      }
    });
    
    // Transform transactions to expected format
    const transformedTransactions: Transaction[] = transactions.map(t => ({
      id: t.externalId,
      merchantRefNum: t.merchantRefNum,
      amount: t.amount,
      currency: t.currency,
      status: t.status as any,
      transactionType: t.transactionType,
      paymentMethod: t.paymentMethod,
      createdAt: t.createdAt.toISOString(),
      updatedAt: t.updatedAt.toISOString(),
      description: t.description || undefined,
    }));
    
    console.log(`‚úÖ Optimized transactions fetched: ${transformedTransactions.length}`);
    
    return {
      success: true,
      transactions: transformedTransactions,
      summary,
    };
  }, { 
    timeout: QUERY_TIMEOUT, 
    operationName: 'get_transactions_optimized',
    retries: 1 // Reduce retries for faster failure
  });
}

async function getOptimizedWebhooks(limit: number, companyId?: string): Promise<any> {
  console.log('üîÑ Fetching optimized webhooks from database...');
  
  return withDatabase(async (db) => {
    const where = companyId ? { companyId } : {};
    
    // Execute queries in parallel
    const [events, stats] = await Promise.all([
      // Get webhook events with selective fields
      db.webhookEvent.findMany({
        where,
        orderBy: { timestamp: 'desc' },
        take: Math.min(limit, 100), // Cap at 100 for performance
        select: {
          id: true,
          timestamp: true,
          eventType: true,
          source: true,
          payload: true,
          processed: true,
          error: true,
        }
      }),
      
      // Get aggregated stats in parallel
      db.webhookEvent.aggregate({
        where,
        _count: { id: true },
        _max: { timestamp: true },
      })
    ]);
    
    // Get processing stats
    const [processedCount, failedCount] = await Promise.all([
      db.webhookEvent.count({ where: { ...where, processed: true } }),
      db.webhookEvent.count({ where: { ...where, error: { not: null } } })
    ]);
    
    // Transform events
    const transformedEvents: WebhookEvent[] = events.map(event => ({
      id: event.id,
      timestamp: event.timestamp.toISOString(),
      eventType: event.eventType,
      source: event.source,
      payload: event.payload as any,
      processed: event.processed,
      error: event.error || undefined,
    }));
    
    const webhookStats = {
      totalReceived: stats._count.id,
      totalProcessed: processedCount,
      totalFailed: failedCount,
      avgProcessingTime: 0, // This would need separate calculation
      lastProcessed: stats._max.timestamp?.toISOString() || null,
    };
    
    console.log(`‚úÖ Optimized webhooks fetched: ${transformedEvents.length}`);
    
    return {
      success: true,
      events: transformedEvents,
      stats: webhookStats,
    };
  }, { 
    timeout: QUERY_TIMEOUT, 
    operationName: 'get_webhooks_optimized',
    retries: 1
  });
}

async function getOptimizedStats(companyId?: string): Promise<any> {
  console.log('üìà Fetching optimized stats from database...');
  
  // Try to get cached analytics first
  const cacheKey = `analytics:optimized:${companyId || 'all'}`;
  
  try {
    const cached = await redis.get(cacheKey);
    if (cached) {
      console.log('‚úÖ Analytics cache hit');
      return JSON.parse(cached);
    }
  } catch (error) {
    console.warn('Analytics cache read failed:', error);
  }
  
  return withDatabase(async (db) => {
    const where = companyId ? { companyId } : {};
    const webhookWhere = companyId ? { companyId } : {};
    
    // Run all aggregations in parallel for maximum performance
    const [
      transactionStats,
      webhookProcessedCount,
      webhookFailedCount,
      totalWebhooks,
      lastProcessedWebhook
    ] = await Promise.all([
      // Transaction statistics
      db.transaction.groupBy({
        by: ['status'],
        where,
        _count: { id: true },
        _sum: { amount: true },
      }),
      
      // Webhook statistics (split for performance)
      db.webhookEvent.count({ where: { ...webhookWhere, processed: true } }),
      db.webhookEvent.count({ where: { ...webhookWhere, error: { not: null } } }),
      db.webhookEvent.count({ where: webhookWhere }),
      db.webhookEvent.findFirst({
        where: { ...webhookWhere, processed: true },
        orderBy: { timestamp: 'desc' },
        select: { timestamp: true }
      })
    ]);
    
    // Process transaction stats
    let totalTransactions = 0;
    let totalAmount = 0;
    const transactionsByStatus: Record<string, number> = {};
    
    transactionStats.forEach(stat => {
      totalTransactions += stat._count.id;
      totalAmount += stat._sum.amount || 0;
      transactionsByStatus[stat.status] = stat._count.id;
    });
    
    const stats = {
      success: true,
      stats: {
        transactions: {
          total: totalTransactions,
          completed: transactionsByStatus['COMPLETED'] || 0,
          failed: transactionsByStatus['FAILED'] || 0,
          pending: transactionsByStatus['PENDING'] || 0,
          totalAmount,
        },
        webhooks: {
          totalReceived: totalWebhooks,
          totalProcessed: webhookProcessedCount,
          totalFailed: webhookFailedCount,
          avgProcessingTime: 0, // Would need separate calculation
          lastProcessed: lastProcessedWebhook?.timestamp.toISOString() || null,
        },
        generatedAt: new Date().toISOString(),
      }
    };
    
    // Cache the stats
    try {
      await redis.setex(cacheKey, CACHE_TTL.stats, JSON.stringify(stats));
    } catch (error) {
      console.warn('Failed to cache analytics:', error);
    }
    
    console.log('‚úÖ Optimized stats calculated');
    
    return stats;
  }, { 
    timeout: QUERY_TIMEOUT, 
    operationName: 'get_stats_optimized',
    retries: 1
  });
}

export async function DELETE() {
  try {
    // Clear all caches
    const cacheKeys = await redis.keys('api:data:*');
    if (cacheKeys.length > 0) {
      await redis.del(...cacheKeys);
    }
    
    // Clear analytics cache
    const analyticsKeys = await redis.keys('analytics:*');
    if (analyticsKeys.length > 0) {
      await redis.del(...analyticsKeys);
    }
    
    // Clear webhook cache
    const webhookKeys = await redis.keys('webhook_events:*');
    if (webhookKeys.length > 0) {
      await redis.del(...webhookKeys);
    }
    
    // Clear database data
    await withDatabase(async (db) => {
      await db.$transaction([
        db.webhookEvent.deleteMany(),
        db.transaction.deleteMany(),
      ]);
    }, { timeout: 10000, operationName: 'clear_all_data' });
    
    return NextResponse.json({
      success: true,
      message: 'All data and caches cleared',
    });
    
  } catch (error) {
    console.error('Error clearing data:', error);
    return NextResponse.json(
      { error: 'Failed to clear data' },
      { status: 500 }
    );
  }
}